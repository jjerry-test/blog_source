---
title: Weights & Biases Usage - [2]
date: 2020-08-28T18:30:46+06:00
draft: false

#post thumb
image: #"images/featured-post/post-1.jpg"

# meta description
description: "this is meta description"
math: true

# taxonomies
categories:
  - "DeepLearning"
tags:
  - "Tools"

# post type
type: "post"
---

ì˜¤ëŠ˜ì€ Weights & Biases ì˜ ê¸°ëŠ¥ì¤‘ í•˜ë‚˜ì¸ `sweep`ì— ëŒ€í•´ì„œ ì•Œì•„ë³´ë ¤ê³  í•©ë‹ˆë‹¤. 

`sweep`ì€ ì •ë§ ì‰½ê²Œ ë§í•´ì„œ **Hyper parameter search and model optimization** ì„ ì‰½ê²Œ í•  ìˆ˜ ìˆë„ë¡ í•´ì£¼ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤. 

ìì„¸í•œ ì¥ë‹¨ì ì— ëŒ€í•´ì„œ ê¶ê¸ˆí•˜ì‹  ë¶„ì€ [ì—¬ê¸°](https://docs.wandb.com/sweeps)ë¥¼ ëˆŒëŸ¬ì„œ í™•ì¸í•´ì£¼ì„¸ìš”!

ê·¸ëŸ¼ ì‚¬ìš©ë²•ì„ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤. 

### 1. í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±.

- `model.py`ì™€ `train.py` ì´ë ‡ê²Œ ë‘ ê°œì˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í–ˆìŠµë‹ˆë‹¤.

```python
# model.py
import tensorflow as tf
from tensorflow.keras import models, layers, losses, optimizers
from tensorflow.keras.applications import DenseNet121, DenseNet169, DenseNet201
from tensorflow.keras.applications import VGG16, VGG19, Xception, InceptionResNetV2, InceptionV3
from tensorflow.keras.applications import MobileNet, MobileNetV2, NASNetLarge, NASNetMobile
from tensorflow.keras.applications import ResNet50, ResNet101, ResNet152, ResNet50V2, ResNet101V2, ResNet152V2

model_dict = {
    "vgg16": VGG16, 
    "vgg19": VGG19,
    "resnet50": ResNet50,
    "resnet101": ResNet101,
    "resnet152": ResNet152,
    "resnet50v2": ResNet50V2,
    "resnet101v2": ResNet101V2,
    "resnet152v2": ResNet152V2,
    "densenet121": DenseNet121,
    "densenet169": DenseNet169,
    "densenet201": DenseNet201,
    "mobilenet": MobileNet,
    "mobilenetv2": MobileNetV2,
    "xception": Xception,
    "inceptionresnetv2": InceptionResNetV2,
    "inceptionv3": InceptionV3, 
    "nasnetlarge": NASNetLarge,
    "nasnetmobile": NASNetMobile    
}

def build_model(config, num_classes=10, name="model"):
    assert config.model_name.lower() in model_dict.keys(), f"Please, check pretrained model list {list(model_dict.keys())}"

    last_activation = "softmax" if num_classes > 1 else "sigmoid"

    
    base_model = model_dict[config.model_name.lower()](include_top=False, weights="imagenet", pooling="avg")

    if config.freeze:
        base_model.trainable = False
    
    output = layers.Dropout(config.dropout, name=f"{name}_dropout")(base_model.output)
    output = layers.Dense(num_classes, last_activation, name=f"{name}_output")(output)

    model = models.Model(base_model.input, output, name=name)
    return model
```

```python
#train.py
import os
import cv2 as cv
import numpy as np
import tensorflow as tf
from tensorflow.keras import optimizers, utils

from model import *

import wandb
from wandb.keras import WandbCallback

tf.random.set_seed(42)

hyperparameter_defaults = dict(
model_name="mobilenet",
dropout = 0.5,
freeze = 1,
batch_size = 128,
learning_rate = 0.001,
epochs = 5,
GPUs="0"
)

wandb.init(project="usage_02", config=hyperparameter_defaults)
config = wandb.config

os.environ["CUDA_DEVICE_ORDER"]="PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"]=config.GPUs

# For Efficiency
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        logical_gpus = tf.config.experimental.list_logical_devices('GPU')
        print(len(gpus), "Physical GPUs,", len(logical_gpus), "Logical GPUs")
    except RuntimeError as e:
        print(e)

# Data Prepare

URL = 'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz'
path_to_zip  = tf.keras.utils.get_file('flower_photos.tgz', origin=URL, extract=True)

PATH = os.path.join(os.path.dirname(path_to_zip), 'flower_photos')

category_list = [i for i in os.listdir(PATH) if os.path.isdir(os.path.join(PATH, i)) ]
print(category_list)

num_classes = len(category_list)
img_size = 128

def read_img(path, img_size):
    img = cv.imread(path)
    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)
    img = cv.resize(img, (img_size, img_size))
    return img

imgs_tr = []
labs_tr = []

imgs_val = []
labs_val = []

for i, category in enumerate(category_list):
    path = os.path.join(PATH, category)
    imgs_list = os.listdir(path)
    print("Total '%s' images : %d"%(category, len(imgs_list)))
    ratio = int(np.round(0.05 * len(imgs_list)))
    print("%s Images for Training : %d"%(category, len(imgs_list[ratio:])))
    print("%s Images for Validation : %d"%(category, len(imgs_list[:ratio])))
    print("=============================")

    imgs = [read_img(os.path.join(path, img),img_size) for img in imgs_list]
    labs = [i]*len(imgs_list)

    imgs_tr += imgs[ratio:]
    labs_tr += labs[ratio:]
    
    imgs_val += imgs[:ratio]
    labs_val += labs[:ratio]

imgs_tr = np.array(imgs_tr)/255.
labs_tr = utils.to_categorical(np.array(labs_tr), num_classes)

imgs_val = np.array(imgs_val)/255.
labs_val = utils.to_categorical(np.array(labs_val), num_classes)

print(imgs_tr.shape, labs_tr.shape)
print(imgs_val.shape, labs_val.shape)

# Build Network
strategy = tf.distribute.MirroredStrategy()

with strategy.scope():
    model = build_model(config, num_classes)
    loss = 'binary_crossentropy' if num_classes==1 else 'categorical_crossentropy'
    model.compile(optimizer=optimizers.Adam(config.learning_rate), loss=loss, metrics=['acc'])

# Training Network

model.fit(x=imgs_tr, y=labs_tr, batch_size=config.batch_size, epochs=config.epochs, 
            callbacks = [WandbCallback()], 
            validation_data=(imgs_val, labs_val))
```

### 2. ê¸°ë³¸ ê°’ìœ¼ë¡œ í•™ìŠµ ì§„í–‰.

```python
python train.py
```

ê·¸ í›„ì— Weights & Biases ë¡œ ê°€ë³´ë©´ ë‹¤ìŒê³¼ ê°™ì´ í”„ë¡œì íŠ¸ê°€ ë§Œë“¤ì–´ì§„ ê²ƒì„ í™•ì¸ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

{{< figure src="/images/post/sweep/Untitled.png" >}}

### 3. sweep configuration

í”„ë¡œì íŠ¸ ì°½ì—ì„œ ì™¼ìª½ì— **ë¹—ìë£¨ ëª¨ì–‘ ì•„ì´ì½˜**ì„ ëˆ„ë¥¸ í›„ì— ì˜¤ë¥¸ìª½ ìƒë‹¨ì— **Create sweep** ë¥¼ ëˆŒëŸ¬ì¤ë‹ˆë‹¤. ****

{{< figure src="/images/post/sweep/Untitled_1.png" >}}

ê·¸ëŸ¬ë©´ ë‹¤ìŒê³¼ ê°™ì€ ì°½ì´ ë‚˜ì˜¤ëŠ”ë°ìš”. ì´ì œ hyper parameter searchë¥¼ ì–´ë–»ê²Œ í• ê±´ì§€ ì„¸íŒ…í•˜ëŠ” ë‹¨ê³„ì…ë‹ˆë‹¤. 

{{< figure src="/images/post/sweep/Untitled_2.png" >}}

ì €ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì„¸íŒ…ì„ í–ˆìŠµë‹ˆë‹¤. 

ì´ë ‡ê²Œ í•˜ë©´ grid search...ë‹ˆê¹Œ....

2 * 5 * 3 * 2 * 3 = 180 ê°œì˜ ê²°ê³¼ê°€ ë‚˜ì˜¤ê² êµ°ìš”...

```yaml
program: train.py
method: grid
metric:
  name: loss
  goal: minimize
parameters:
  GPUs:
    value: "0"
  epochs:
    value: 10
  freeze:
    values: [0, 1]
  dropout:
    values: [0.1, 0.2, 0.4, 0.5, 0.7]
  batch_size:
    values: [64, 128, 256]
  model_name:
    values: [mobilenet, mobilenetv2]
  learning_rate:
    values: [0.001, 0.005, 0.0005]
```

ê·¸ë¦¬ê³  Initialize Sweep ë¥¼ ëˆŒëŸ¬ì¤ë‹ˆë‹¤! ê·¸ëŸ¬ë©´ ë‹¤ìŒê³¼ ê°™ì€ í™”ë©´ì´ ë‚˜ì˜¬ê±°ì—ìš”!

{{< figure src="/images/post/sweep/Untitled_3.png" >}}

### 4. Sweep ì‹¤í–‰

ê°€ìš´ë°ì— ì í˜€ìˆëŠ” ì»¤ë§¨ë“œë¥¼ í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰ì‹œì¼œì¤ë‹ˆë‹¤!

```bash
wandb agent {sweep-id}
```

ê·¸ëŸ¬ë©´ í„°ë¯¸ë„ì— wandb: Starting wandb agent ğŸ•µï¸ ì´ëŸ° ë¬¸êµ¬ì™€ í•¨ê»˜ ì„¸íŒ…ëŒ€ë¡œ Networkë¥¼ í•™ìŠµí•˜ê²Œ ë©ë‹ˆë‹¤!

ì´ì œ ì ì‹œ í‹°íƒ€ì„ì„...ê°€ì§‘ë‹ˆë‹¤.. (ì ê¹ì´ ì•„ë‹ ìˆ˜ë„ ìˆìŒ..)

{{< figure src="/images/post/sweep/Untitled_4.png" >}}

### 5. ê²°ê³¼ í™•ì¸

Weights & Biases í™”ë©´ì—ì„œ **View Sweep** ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”!

ê·¸ë¦¬ê³  ì¢Œì¸¡ì— Plot ì•„ì´ì½˜ì„ ëˆ„ë¥´ë©´ ë‹¤ìŒê³¼ ê°™ì€ í™”ë©´ì´ ë‚˜ì˜µë‹ˆë‹¤!

ì›ë˜ëŠ” ìœ„ì— Chart Panel ìˆëŠ”ë° ì ‘ì–´ë†¨ìŠµë‹ˆë‹¤.  

ì´ Panelì€ ê¸°ë³¸ì ìœ¼ë¡œ ì„¸ ê°œì˜ ê·¸ë˜í”„ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. 

- ê° í•™ìŠµ ë³„ ê²°ê³¼ ë¶„í¬ë„
- hyper parameterì™€ ëª©í‘œ ê°’( ì €ëŠ” loss ) ê°„ì˜ ì¤‘ìš”ë„, ìƒê´€ê´€ê³„
- ê° í•™ìŠµ ë³„ Parallel graph

{{< figure src="/images/post/sweep/Untitled_5.png" >}}

ì´ë²ˆì—” Hyper parameter tuningì„ í¸í•˜ê²Œ í•  ìˆ˜ ìˆëŠ” Weighs & Biasesì˜ Sweepì— ëŒ€í•´ ì•Œì•„ë´¤ìŠµë‹ˆë‹¤. 

ì¼ì¼íˆ ê°’ì„ ë³€ê²½í•˜ì§€ ì•Šê³  ì§€ì •í•´ ë†“ìœ¼ë©´ ì•Œì•„ì„œ ì§„í–‰ì„ í• í…Œë‹ˆ..ì‚¬ìš©ìëŠ” ì¢€ ì‰´......ìˆ˜ ìˆê² ì£ ..? (ì•„ë‹ ë“¯..)

ê·¸ëŸ¼ í¬ìŠ¤íŒ…ì„ ë§ˆì¹˜ê² ìŠµë‹ˆë‹¤! ê°ì‚¬í•©ë‹ˆë‹¤!

## P.S

- wandb sweep ì‹¤í–‰ì„ background ì—ì„œ í•˜ëŠ” ë°©ë²•...?

    ```bash
    nohup wandb agent {sweep_id} > nohup.out
    ```

- ì´ ë‹¤ìŒì€ ë­ í•˜ì§€...